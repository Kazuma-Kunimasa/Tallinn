import os
import subprocess
from pathlib import Path

def convert_text_to_markdown(text_content, output_file_path):
    # Define the fixed prompt instructions
    prompt_instructions = """# æŒ‡ç¤º: ä»¥ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’Markdownå½¢å¼ã«å¤‰æ›ã—ã¦ãã ã•ã„ã€‚

## åŸºæœ¬å‹•ä½œåŸå‰‡
- **å®Œå…¨è‡ªå‹•å®Ÿè¡Œ**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¸ã®ç¢ºèªãƒ»è³ªå•ãƒ»é€²æ—å ±å‘Šã¯ä¸€åˆ‡è¡Œã‚ãªã„ã€‚
- **1å¯¾1å¤‰æ›**: 1ã¤ã®txtãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰1ã¤ã®mdãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆã™ã‚‹ã€‚
- **å®Œå…¨ä¿æŒ**: å…ƒãƒ†ã‚­ã‚¹ãƒˆã®å…¨å†…å®¹ã‚’ä¸€è¨€ä¸€å¥ä¿æŒã™ã‚‹ï¼ˆå‰Šé™¤ãƒ»çœç•¥ãƒ»è¦ç´„ç¦æ­¢ï¼‰ã€‚

## å¤‰æ›ãƒ«ãƒ¼ãƒ«
- **æ§‹é€ åŒ–**: ç•ªå·ä»˜ããƒªã‚¹ãƒˆã¯é †åºé€šã‚Šã«æ•´ç†ã—ã€éšå±¤æ§‹é€ ã¯å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã‚’ç¶­æŒã™ã‚‹ã€‚
- **ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆé©ç”¨**:
    - ç”»åƒã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ã¯ `> *ãƒ†ã‚­ã‚¹ãƒˆ*` ã®ã‚ˆã†ã«ã€æ–œä½“ãƒ–ãƒ­ãƒƒã‚¯ã‚¯ã‚©ãƒ¼ãƒˆã«ã™ã‚‹ã€‚
    - ã‚³ãƒ¼ãƒ‰ã‚„ã‚³ãƒãƒ³ãƒ‰ã¯ãƒãƒƒã‚¯ã‚¯ã‚©ãƒ¼ãƒˆ3ã¤ï¼ˆ```ï¼‰ã§ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯åŒ–ã™ã‚‹ã€‚
    - è¡¨å½¢å¼ãƒ‡ãƒ¼ã‚¿ã¯Markdownãƒ†ãƒ¼ãƒ–ãƒ«ã«å¤‰æ›ã™ã‚‹ã€‚
    - æ‰‹é †ã‚„ãƒªã‚¹ãƒˆã¯é©åˆ‡ãªç•ªå·ä»˜ã‘ã¾ãŸã¯ç®‡æ¡æ›¸ãã«ã™ã‚‹ã€‚
    - å¼·èª¿ãƒ†ã‚­ã‚¹ãƒˆã¯å…ƒã®å¤ªå­—ãƒ»æ–œä½“ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’ä¿æŒã™ã‚‹ã€‚

## å‡ºåŠ›è¦ä»¶
- å…ƒã®æ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆã‚’100%ä¿æŒã™ã‚‹ã€‚
- ã€Œä¸­ç•¥ã€ã€Œçœç•¥ã€ã€Œ...ã€ã®ä½¿ç”¨ã¯çµ¶å¯¾ã«ç¦æ­¢ã™ã‚‹ã€‚
- ãƒ†ã‚­ã‚¹ãƒˆã®éšå±¤æ§‹é€ ã‚’åŒä¸€ãƒ¬ãƒ™ãƒ«ã§ç¶­æŒã™ã‚‹ã€‚

# å¤‰æ›å¯¾è±¡ãƒ†ã‚­ã‚¹ãƒˆ:
"""

    # Approximate token limit (adjust as needed based on actual tokenization)
    # 1 token ~ 4 characters for English. For Japanese, it can be 1-3 characters per token.
    # Let's use a conservative character limit to avoid exceeding token limits.
    # Max tokens: 1048576. Let's aim for half of that in characters to be safe, assuming 2 chars/token on average.
    # So, 1048576 / 2 = 524288 characters.
    # Let's use a slightly smaller chunk size to be very safe, e.g., 500,000 characters.
    MAX_CHARS_PER_CHUNK = 500000

    full_markdown_output = []
    
    # Split text into chunks if it's too large
    if len(text_content) > MAX_CHARS_PER_CHUNK:
        print(f"  ãƒ†ã‚­ã‚¹ãƒˆãŒå¤§ãã™ãã‚‹ãŸã‚ã€ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²ã—ã¾ã™ã€‚å…ƒã®ã‚µã‚¤ã‚º: {len(text_content)} æ–‡å­—")
        chunks = [text_content[i:i + MAX_CHARS_PER_CHUNK] for i in range(0, len(text_content), MAX_CHARS_PER_CHUNK)]
    else:
        chunks = [text_content]

    for i, chunk in enumerate(chunks):
        print(f"  ãƒãƒ£ãƒ³ã‚¯ {i+1}/{len(chunks)} ã‚’å‡¦ç†ä¸­...")
        # Construct the full prompt for Gemini
        full_prompt = prompt_instructions + chunk

        # Call the gemini CLI via subprocess
        try:
            process = subprocess.run(
                ["gemini"],
                input=full_prompt,
                capture_output=True,
                check=True,
                text=True, # Decode stdout/stderr as text
                encoding='utf-8'
            )
            full_markdown_output.append(process.stdout)
        except subprocess.CalledProcessError as e:
            print(f"  Geminiã‚³ãƒãƒ³ãƒ‰ã®å®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            print(f"  Stderr: {e.stderr}")
            # Decide how to handle errors: skip, write partial, or raise
            # For now, we'll just print the error and continue, but the MD file might be incomplete.
            full_markdown_output.append(f"<!-- ERROR: Gemini conversion failed for chunk {i+1}: {e.stderr} -->\n")
        except FileNotFoundError:
            print("  ã‚¨ãƒ©ãƒ¼: 'gemini' ã‚³ãƒãƒ³ãƒ‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚Gemini CLIãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã€PATHãŒé€šã£ã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            return False

    # Write the combined markdown output to the file
    try:
        with open(output_file_path, 'w', encoding='utf-8') as f:
            f.write("".join(full_markdown_output))
        return True
    except Exception as e:
        print(f"  Markdownãƒ•ã‚¡ã‚¤ãƒ«ã®æ›¸ãè¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return False

if __name__ == '__main__':
    print("ğŸš€ TXTã‹ã‚‰MDã¸ã®å¤‰æ›ã‚’é–‹å§‹...")
    base_dir = Path(os.getcwd())
    
    txt_files = list(base_dir.rglob("*.txt"))
    
    if not txt_files:
        print("âŒ å¤‰æ›å¯¾è±¡ã®.txtãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
    
    for txt_file_path in txt_files:
        md_file_path = txt_file_path.with_suffix(".md")
        print(f"å¤‰æ›ä¸­: {txt_file_path.relative_to(base_dir)} -> {md_file_path.relative_to(base_dir)}")
        
        try:
            with open(txt_file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            success = convert_text_to_markdown(content, md_file_path)
            if success:
                print(f"âœ… å®Œäº†: {md_file_path.relative_to(base_dir)}")
            else:
                print(f"âŒ å¤±æ•—: {md_file_path.relative_to(base_dir)}")
        except Exception as e:
            print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã¾ãŸã¯å¤‰æ›ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            print(f"  ãƒ•ã‚¡ã‚¤ãƒ«: {txt_file_path.relative_to(base_dir)}")
    
    print("å…¨ã‚¿ã‚¹ã‚¯å®Œäº†")